{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST  \n",
    "`pip install ipywidgets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "[5 0 4 ... 5 6 8]\n",
      "(10000, 28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\anaconda3\\envs\\AI_course\\lib\\site-packages\\torchvision\\datasets\\mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "c:\\Users\\Student\\anaconda3\\envs\\AI_course\\lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import mnist\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "def data_transform(x):\n",
    "    x = np.array(x, dtype = 'float32') / 255\n",
    "    x = x.reshape((-1, ))\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "trainset = mnist.MNIST('./dataset/mnist', train=True, transform=data_transform, download=True)\n",
    "testset = mnist.MNIST('./dataset/mnist', train = False, transform=data_transform, download=True)\n",
    "\n",
    "train_data = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "print(len(trainset.train_data))\n",
    "print(trainset.train_data.numpy().shape)\n",
    "print(trainset.train_labels.numpy().shape)\n",
    "print(trainset.train_labels.numpy())\n",
    "print(testset.test_data.numpy().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b058aceac0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(trainset.train_data[0].numpy(),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n",
      "torch.Size([64])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([4, 5, 0, 8, 0, 7, 4, 7, 8, 0, 7, 5, 3, 4, 2, 6, 3, 0, 6, 8, 5, 7, 5, 3,\n",
      "        8, 9, 9, 1, 8, 6, 9, 8, 1, 1, 5, 3, 5, 0, 1, 1, 5, 5, 9, 8, 9, 6, 1, 3,\n",
      "        7, 8, 0, 2, 4, 0, 6, 8, 0, 3, 0, 1, 9, 1, 7, 2])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_data:\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    print(images)\n",
    "    print(labels)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DNN Model(Functional API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "DNN(\n",
      "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=250, bias=True)\n",
      "  (fc3): Linear(in_features=250, out_features=125, bias=True)\n",
      "  (fc4): Linear(in_features=125, out_features=10, bias=True)\n",
      ")\n",
      "<class 'torch.Tensor'> torch.Size([500, 784])\n",
      "<class 'torch.Tensor'> torch.Size([500])\n",
      "<class 'torch.Tensor'> torch.Size([250, 500])\n",
      "<class 'torch.Tensor'> torch.Size([250])\n",
      "<class 'torch.Tensor'> torch.Size([125, 250])\n",
      "<class 'torch.Tensor'> torch.Size([125])\n",
      "<class 'torch.Tensor'> torch.Size([10, 125])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "torch.Size([500, 784])\n",
      "torch.Size([500])\n",
      "torch.Size([250, 500])\n",
      "Parameter containing:\n",
      "tensor([[-0.0085,  0.0009, -0.0146,  ..., -0.0120, -0.0346, -0.0272],\n",
      "        [-0.0277,  0.0083,  0.0232,  ..., -0.0289, -0.0001, -0.0325],\n",
      "        [-0.0341,  0.0300, -0.0349,  ...,  0.0079, -0.0115,  0.0010],\n",
      "        ...,\n",
      "        [ 0.0177, -0.0335,  0.0167,  ..., -0.0242,  0.0011,  0.0193],\n",
      "        [ 0.0305,  0.0256,  0.0172,  ...,  0.0198,  0.0156,  0.0285],\n",
      "        [ 0.0164, -0.0110,  0.0262,  ...,  0.0111,  0.0172, -0.0286]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "from torchvision.datasets import mnist\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "%matplotlib inline\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__() # copy父類別的初始化函數\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 250)\n",
    "        self.fc3 = nn.Linear(250, 125)\n",
    "        self.fc4 = nn.Linear(125, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# build model\n",
    "model = DNN().to(device)  # (cuda)搬到gpu\n",
    "print(model)\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())\n",
    "    \n",
    "param_list = list(model.parameters())\n",
    "print(param_list[0].shape)\n",
    "print(param_list[1].shape)\n",
    "print(param_list[2].shape)\n",
    "print(param_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DNN Model(Sequential API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "DNN(\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=500, out_features=250, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=250, out_features=125, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=125, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "<class 'torch.Tensor'> torch.Size([500, 784])\n",
      "<class 'torch.Tensor'> torch.Size([500])\n",
      "<class 'torch.Tensor'> torch.Size([250, 500])\n",
      "<class 'torch.Tensor'> torch.Size([250])\n",
      "<class 'torch.Tensor'> torch.Size([125, 250])\n",
      "<class 'torch.Tensor'> torch.Size([125])\n",
      "<class 'torch.Tensor'> torch.Size([10, 125])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "torch.Size([500, 784])\n",
      "torch.Size([500])\n",
      "Parameter containing:\n",
      "tensor([[-0.0048,  0.0262, -0.0140,  ...,  0.0217,  0.0120, -0.0217],\n",
      "        [ 0.0254, -0.0006,  0.0246,  ..., -0.0139,  0.0357,  0.0093],\n",
      "        [ 0.0316,  0.0010,  0.0014,  ..., -0.0099,  0.0081, -0.0181],\n",
      "        ...,\n",
      "        [-0.0350, -0.0118, -0.0038,  ...,  0.0103, -0.0003, -0.0098],\n",
      "        [-0.0288, -0.0297, -0.0190,  ...,  0.0178, -0.0316,  0.0255],\n",
      "        [ 0.0034, -0.0260,  0.0310,  ..., -0.0018, -0.0184, -0.0163]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "from torchvision.datasets import mnist\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "                   nn.Linear(28*28, 500),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(500, 250),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(250, 125),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(125, 10)\n",
    "                   )\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        self.seq = nn.Sequential()\n",
    "        self.seq.add_module('FC1', nn.Linear(28*28, 500))\n",
    "        self.seq.add_module('AC1', nn.ReLU())\n",
    "        self.seq.add_module('FC2', nn.Linear(500, 250))\n",
    "        self.seq.add_module('AC2', nn.ReLU())\n",
    "        self.seq.add_module('FC3', nn.Linear(250, 125))\n",
    "        self.seq.add_module('AC3', nn.ReLU())\n",
    "        self.seq.add_module('FC4', nn.Linear(125, 10))\n",
    "        self.seq.add_module('AC4', nn.ReLU())\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        self.seq = nn.Sequential(\n",
    "                 OrderedDict([\n",
    "                 ('FC1', nn.Linear(28*28, 500)),\n",
    "                 ('AC1', nn.ReLU()),\n",
    "                 ('FC2', nn.Linear(500, 250)),\n",
    "                 ('AC2', nn.ReLU()),\n",
    "                 ('FC3', nn.Linear(250, 125)),\n",
    "                 ('AC3', nn.ReLU()),\n",
    "                 ('FC4', nn.Linear(120, 10)),\n",
    "                 ('AC4', nn.ReLU())\n",
    "                 ]\n",
    "                 ))\n",
    "        \n",
    "         '''\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "        \n",
    "# build model\n",
    "model = DNN().to(device)\n",
    "print(model)\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())\n",
    "    \n",
    "print(model.seq[0].weight.shape)\n",
    "print(model.seq[0].bias.shape)\n",
    "print(model.seq[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DNN Model(ModuleList API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "DNN(\n",
      "  (modlist): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=500, out_features=250, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=250, out_features=125, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=125, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "<class 'torch.Tensor'> torch.Size([500, 784])\n",
      "<class 'torch.Tensor'> torch.Size([500])\n",
      "<class 'torch.Tensor'> torch.Size([250, 500])\n",
      "<class 'torch.Tensor'> torch.Size([250])\n",
      "<class 'torch.Tensor'> torch.Size([125, 250])\n",
      "<class 'torch.Tensor'> torch.Size([125])\n",
      "<class 'torch.Tensor'> torch.Size([10, 125])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "torch.Size([500, 784])\n",
      "torch.Size([500])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0249, -0.0107,  0.0134,  ..., -0.0014,  0.0177,  0.0209],\n",
      "        [ 0.0152,  0.0349,  0.0284,  ...,  0.0334,  0.0255,  0.0093],\n",
      "        [-0.0315, -0.0025,  0.0076,  ..., -0.0033, -0.0262, -0.0301],\n",
      "        ...,\n",
      "        [-0.0193,  0.0228, -0.0206,  ..., -0.0259, -0.0147, -0.0113],\n",
      "        [-0.0320, -0.0147,  0.0197,  ..., -0.0144, -0.0305,  0.0132],\n",
      "        [ 0.0056,  0.0291,  0.0202,  ..., -0.0090,  0.0252, -0.0098]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "from torchvision.datasets import mnist\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.modlist = nn.ModuleList([\n",
    "                       nn.Linear(28*28, 500),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(500, 250),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(250, 125),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(125, 10)\n",
    "                       ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for m in self.modlist:\n",
    "            x = m(x)\n",
    "        return x\n",
    "        \n",
    "# build model\n",
    "model = DNN().to(device)\n",
    "print(model)\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())\n",
    "    \n",
    "    \n",
    "\n",
    "print(model.modlist[0].weight.shape)\n",
    "print(model.modlist[0].bias.shape)\n",
    "print(model.modlist[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization \n",
    "網路初始化方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "DNN(\n",
      "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=250, bias=True)\n",
      "  (fc3): Linear(in_features=250, out_features=125, bias=True)\n",
      "  (fc4): Linear(in_features=125, out_features=10, bias=True)\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[-3.3977e-02, -5.9964e-03, -4.1390e-02,  ...,  7.4225e-02,\n",
      "         -1.3031e-02, -8.4928e-04],\n",
      "        [-3.2413e-02, -3.6203e-02, -2.2609e-02,  ...,  3.6485e-02,\n",
      "          2.7804e-02, -2.4382e-02],\n",
      "        [ 1.7716e-02, -5.5219e-02,  3.6093e-02,  ..., -6.9860e-03,\n",
      "         -3.2834e-02,  7.6802e-03],\n",
      "        ...,\n",
      "        [ 7.8728e-02, -9.8865e-02,  2.4167e-03,  ..., -4.7998e-03,\n",
      "          5.0595e-02,  5.7985e-02],\n",
      "        [-8.2443e-02,  6.2747e-02,  3.0919e-02,  ..., -6.3668e-03,\n",
      "         -3.6495e-02, -5.2290e-03],\n",
      "        [ 7.2647e-02, -4.2568e-03, -6.5195e-05,  ..., -1.2419e-02,\n",
      "         -1.1391e-01,  4.3950e-02]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "from torchvision.datasets import mnist\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "%matplotlib inline\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 250)\n",
    "        self.fc3 = nn.Linear(250, 125)\n",
    "        self.fc4 = nn.Linear(125, 10)\n",
    "        \n",
    "        \n",
    "        # Initialization\n",
    "        #nn.init.normal_(self.fc1.weight)\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "        nn.init.xavier_normal_(self.fc3.weight)\n",
    "        nn.init.xavier_normal_(self.fc4.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# build model\n",
    "model = DNN().to(device)\n",
    "print(model)\n",
    "\n",
    "    \n",
    "param_list = list(model.parameters())\n",
    "\n",
    "print(param_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Parameter containing:\n",
      "tensor([[ 0.1160,  0.0005,  0.0415,  ...,  0.0437, -0.0295,  0.0296],\n",
      "        [ 0.0006, -0.0412, -0.0158,  ...,  0.0108,  0.0201, -0.0402],\n",
      "        [ 0.0026,  0.0310, -0.0046,  ..., -0.0235, -0.0402,  0.0276],\n",
      "        ...,\n",
      "        [ 0.0003,  0.0330,  0.0223,  ..., -0.0645,  0.0176,  0.0278],\n",
      "        [-0.0173,  0.0272, -0.0035,  ...,  0.0736, -0.0189,  0.0045],\n",
      "        [-0.0054,  0.0430, -0.0345,  ..., -0.0707, -0.0107, -0.0598]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "from torchvision.datasets import mnist\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "%matplotlib inline\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 250)\n",
    "        self.fc3 = nn.Linear(250, 125)\n",
    "        self.fc4 = nn.Linear(125, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# build model\n",
    "model = DNN().to(device)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        #nn.init.normal_(m.weight)\n",
    "\n",
    "# Applying it to our net\n",
    "model.apply(init_weights)\n",
    "\n",
    "param_list = list(model.parameters())\n",
    "\n",
    "print(param_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 10])\n",
      "tensor([[ 4.7740e-02,  7.7388e-02, -1.5774e-02,  5.7297e-03,  8.7687e-02,\n",
      "          5.5982e-02,  2.1239e-02, -3.7160e-02,  3.0705e-02,  9.0413e-02],\n",
      "        [ 6.7914e-02,  8.7243e-02, -1.3819e-02,  1.3058e-02,  8.9838e-02,\n",
      "          7.1089e-02,  3.2113e-03, -3.6856e-02,  1.4967e-02,  9.0257e-02],\n",
      "        [ 5.4157e-02,  1.0005e-01, -1.9878e-02,  1.7116e-02,  1.0046e-01,\n",
      "          6.7687e-02,  1.8524e-02, -5.0553e-02,  1.9709e-02,  7.3317e-02],\n",
      "        [ 6.3270e-02,  8.2398e-02, -1.9028e-02,  3.8163e-02,  9.3198e-02,\n",
      "          8.9728e-02,  1.7065e-02, -4.1504e-02, -1.0454e-02,  8.8586e-02],\n",
      "        [ 6.5213e-02,  8.8408e-02, -2.1530e-02,  3.0140e-02,  9.1325e-02,\n",
      "          7.1145e-02,  1.9618e-02, -3.5486e-02, -3.9390e-03,  8.1932e-02],\n",
      "        [ 6.8698e-02,  9.5727e-02, -2.1603e-02,  2.0402e-02,  8.4289e-02,\n",
      "          5.6221e-02,  2.0887e-02, -3.4621e-02,  7.8740e-03,  8.4365e-02],\n",
      "        [ 5.2605e-02,  8.2289e-02, -3.5958e-02,  2.6843e-02,  8.3488e-02,\n",
      "          7.7902e-02,  3.7642e-03, -3.9018e-02,  1.5713e-03,  9.1051e-02],\n",
      "        [ 6.2036e-02,  7.5753e-02, -1.2094e-02,  1.1568e-02,  9.5949e-02,\n",
      "          6.0030e-02,  1.9529e-02, -4.8713e-02,  2.7219e-03,  8.6717e-02],\n",
      "        [ 7.4305e-02,  8.6552e-02, -1.2659e-02,  3.0464e-02,  8.8456e-02,\n",
      "          7.7222e-02,  2.2904e-02, -4.2732e-02, -3.6078e-03,  8.2010e-02],\n",
      "        [ 4.8492e-02,  8.0368e-02, -2.5580e-02,  1.7176e-02,  9.6537e-02,\n",
      "          5.7967e-02,  1.8638e-02, -4.1385e-02,  9.0695e-03,  8.1920e-02],\n",
      "        [ 7.4716e-02,  7.6703e-02, -1.4371e-02,  2.8310e-02,  8.2558e-02,\n",
      "          6.7252e-02,  2.0692e-02, -4.3683e-02,  5.8268e-03,  9.4733e-02],\n",
      "        [ 5.4533e-02,  9.4821e-02, -8.8898e-03,  5.1145e-05,  7.5555e-02,\n",
      "          5.0699e-02,  1.2238e-02, -2.3144e-02,  2.6933e-02,  8.6527e-02],\n",
      "        [ 6.4969e-02,  8.9620e-02, -1.6031e-02,  1.8680e-02,  8.3216e-02,\n",
      "          6.0438e-02,  2.9664e-02, -3.5009e-02,  2.0122e-02,  8.4512e-02],\n",
      "        [ 5.6931e-02,  7.5994e-02, -1.3696e-02,  9.6190e-03,  8.4846e-02,\n",
      "          6.7720e-02,  2.0358e-02, -2.8331e-02,  1.4383e-02,  9.6590e-02],\n",
      "        [ 6.9069e-02,  9.4144e-02, -1.5791e-02,  3.5112e-02,  9.6315e-02,\n",
      "          7.0751e-02,  2.7799e-02, -4.1776e-02, -1.1010e-02,  8.3574e-02],\n",
      "        [ 5.3389e-02,  1.0010e-01, -1.2063e-02,  3.2169e-02,  9.2465e-02,\n",
      "          7.0173e-02,  1.6710e-02, -3.2139e-02,  5.4858e-03,  7.9828e-02],\n",
      "        [ 8.2164e-02,  7.8670e-02, -9.5886e-03,  1.1396e-02,  9.7545e-02,\n",
      "          6.7726e-02,  2.6392e-02, -5.3287e-02, -1.6390e-02,  8.7941e-02],\n",
      "        [ 7.5447e-02,  9.4556e-02, -1.0040e-02,  1.8335e-02,  9.7190e-02,\n",
      "          7.0069e-02,  9.5009e-03, -4.1949e-02, -6.9400e-03,  7.2870e-02],\n",
      "        [ 6.7266e-02,  7.7507e-02, -1.7308e-02,  3.2639e-02,  9.5640e-02,\n",
      "          7.3254e-02,  2.5991e-02, -3.9202e-02,  6.7504e-03,  8.6290e-02],\n",
      "        [ 5.6534e-02,  7.7843e-02, -1.2839e-02,  7.0746e-03,  1.1622e-01,\n",
      "          6.7429e-02,  2.0135e-02, -5.4944e-02,  9.0615e-03,  1.0065e-01],\n",
      "        [ 5.5557e-02,  8.1434e-02, -3.2427e-02,  2.1626e-02,  9.1984e-02,\n",
      "          7.2685e-02,  3.7899e-02, -3.4849e-02,  1.7618e-02,  9.2220e-02],\n",
      "        [ 7.3208e-02,  9.2515e-02, -3.9636e-03,  2.6227e-02,  9.6913e-02,\n",
      "          7.8341e-02,  4.0095e-03, -3.7182e-02,  3.7206e-03,  8.5620e-02],\n",
      "        [ 6.7574e-02,  7.4982e-02, -1.0064e-02,  1.6434e-02,  1.0125e-01,\n",
      "          6.6010e-02,  2.3887e-02, -5.0173e-02,  3.4955e-03,  8.9424e-02],\n",
      "        [ 5.8931e-02,  9.6959e-02, -9.8824e-03,  1.6543e-02,  8.6359e-02,\n",
      "          6.5416e-02,  2.5843e-02, -2.6748e-02,  1.1646e-02,  8.8908e-02],\n",
      "        [ 6.0933e-02,  9.5907e-02, -1.5920e-02,  3.0369e-02,  9.3777e-02,\n",
      "          7.8133e-02,  2.8914e-02, -3.2514e-02, -6.9565e-03,  9.4219e-02],\n",
      "        [ 6.8477e-02,  1.0002e-01, -1.1587e-02,  1.6224e-02,  9.2157e-02,\n",
      "          5.0080e-02,  1.9444e-02, -5.0009e-02,  1.5144e-02,  8.1390e-02],\n",
      "        [ 4.7711e-02,  8.4373e-02, -2.9502e-03,  7.7472e-03,  8.6159e-02,\n",
      "          5.0842e-02,  1.6326e-02, -3.2215e-02,  7.4166e-03,  7.8402e-02],\n",
      "        [ 7.1260e-02,  8.3883e-02, -1.6127e-02,  2.1011e-02,  9.1839e-02,\n",
      "          6.3386e-02,  1.9840e-02, -3.6389e-02,  1.3095e-03,  9.2214e-02],\n",
      "        [ 5.4313e-02,  9.1061e-02, -1.2726e-02,  2.6609e-02,  9.2952e-02,\n",
      "          6.5160e-02,  1.9837e-02, -3.4801e-02,  9.6227e-03,  8.1111e-02],\n",
      "        [ 6.1987e-02,  9.1843e-02, -1.4317e-02,  2.5505e-02,  9.5229e-02,\n",
      "          6.7412e-02,  3.0589e-02, -3.4781e-02,  5.2906e-03,  8.9983e-02],\n",
      "        [ 7.2818e-02,  9.8636e-02,  2.9718e-03,  1.4984e-02,  8.6951e-02,\n",
      "          6.4098e-02,  6.4274e-03, -3.5750e-02,  7.8956e-03,  8.1255e-02],\n",
      "        [ 5.0266e-02,  9.1220e-02, -2.9329e-02,  2.4651e-02,  9.7757e-02,\n",
      "          6.9498e-02,  1.8914e-02, -3.0299e-02,  1.1275e-02,  9.0484e-02],\n",
      "        [ 5.8582e-02,  9.0097e-02, -1.9137e-02,  3.3513e-02,  9.6854e-02,\n",
      "          6.4545e-02,  2.3941e-02, -4.5465e-02, -7.0541e-03,  8.9182e-02],\n",
      "        [ 6.9002e-02,  9.5590e-02, -1.7401e-02,  2.5374e-02,  9.4395e-02,\n",
      "          7.7549e-02,  3.5186e-02, -4.0700e-02, -2.6910e-04,  8.6749e-02],\n",
      "        [ 7.2595e-02,  9.3564e-02, -1.6756e-02,  3.6657e-02,  9.3821e-02,\n",
      "          6.6411e-02,  1.4364e-02, -3.7265e-02, -4.2092e-03,  8.7482e-02],\n",
      "        [ 5.2794e-02,  9.7922e-02, -1.6538e-02,  2.3843e-02,  1.0307e-01,\n",
      "          5.4387e-02,  2.6116e-02, -2.9549e-02,  5.3268e-03,  8.7715e-02],\n",
      "        [ 6.7720e-02,  9.1300e-02, -1.7530e-02,  3.4091e-02,  9.1935e-02,\n",
      "          7.1268e-02,  3.2203e-02, -3.1333e-02, -5.4527e-03,  8.6965e-02],\n",
      "        [ 6.6535e-02,  7.7509e-02, -6.9196e-03,  1.5381e-02,  9.8294e-02,\n",
      "          6.3445e-02,  2.1279e-02, -3.5032e-02,  1.6624e-02,  7.9881e-02],\n",
      "        [ 5.1321e-02,  8.1700e-02, -2.5353e-02,  2.4375e-02,  8.4330e-02,\n",
      "          6.4761e-02,  2.8358e-02, -3.3708e-02, -1.2161e-02,  8.8550e-02],\n",
      "        [ 6.4829e-02,  8.4432e-02, -2.4454e-02,  3.1070e-02,  8.8413e-02,\n",
      "          8.2637e-02,  2.6972e-02, -4.3059e-02, -7.4578e-03,  8.6884e-02],\n",
      "        [ 6.4135e-02,  9.7041e-02, -1.1589e-02,  1.4828e-02,  1.0062e-01,\n",
      "          5.0525e-02,  1.7524e-02, -2.9106e-02,  2.6068e-03,  8.6915e-02],\n",
      "        [ 7.1585e-02,  1.0132e-01, -1.0677e-02,  1.7458e-02,  8.9584e-02,\n",
      "          4.9370e-02,  6.8525e-03, -4.2868e-02,  9.7227e-03,  7.5066e-02],\n",
      "        [ 6.0055e-02,  8.1558e-02, -1.8640e-02,  1.5544e-02,  8.0482e-02,\n",
      "          6.4707e-02, -6.5329e-04, -4.2337e-02,  1.5168e-02,  8.4040e-02],\n",
      "        [ 5.7954e-02,  7.2147e-02, -9.6327e-03,  1.2714e-02,  7.6094e-02,\n",
      "          6.0908e-02,  2.4193e-02, -3.3187e-02,  1.9646e-02,  9.2872e-02],\n",
      "        [ 6.2418e-02,  9.5260e-02, -2.1483e-02,  1.5543e-02,  9.1302e-02,\n",
      "          5.7781e-02,  2.7104e-02, -3.8181e-02,  1.2585e-02,  9.3157e-02],\n",
      "        [ 7.3389e-02,  8.3450e-02, -2.5789e-02,  6.7409e-03,  1.0100e-01,\n",
      "          6.5025e-02,  3.6651e-02, -4.6528e-02,  8.7834e-04,  8.2450e-02],\n",
      "        [ 7.6810e-02,  9.3695e-02, -1.1284e-02,  3.6886e-02,  8.3471e-02,\n",
      "          7.5635e-02,  2.0061e-02, -3.7062e-02, -9.2341e-03,  8.5432e-02],\n",
      "        [ 6.0697e-02,  7.9299e-02, -2.2850e-02,  1.8342e-02,  1.0628e-01,\n",
      "          8.0059e-02,  2.8626e-02, -4.9675e-02, -1.3024e-03,  8.7715e-02],\n",
      "        [ 6.5379e-02,  8.8666e-02, -2.0389e-02,  2.4127e-02,  9.6127e-02,\n",
      "          6.5735e-02,  1.8746e-02, -4.3977e-02,  1.6934e-03,  8.6686e-02],\n",
      "        [ 6.4080e-02,  8.2085e-02, -1.6030e-02,  2.6322e-02,  1.0086e-01,\n",
      "          6.6910e-02,  2.4764e-02, -4.6283e-02,  1.3110e-02,  8.2473e-02],\n",
      "        [ 5.1991e-02,  1.0568e-01, -9.3652e-03,  1.6874e-02,  9.5341e-02,\n",
      "          6.1309e-02,  8.9800e-03, -3.7394e-02,  8.9489e-03,  7.9161e-02],\n",
      "        [ 6.9442e-02,  8.0889e-02, -1.2203e-02,  5.5902e-03,  9.9043e-02,\n",
      "          7.0494e-02, -4.4049e-03, -4.4151e-02,  2.1434e-02,  7.4684e-02],\n",
      "        [ 7.5304e-02,  9.0170e-02, -2.2436e-02,  3.2377e-02,  1.0081e-01,\n",
      "          7.3553e-02,  1.0703e-02, -4.6472e-02,  6.7473e-04,  8.6712e-02],\n",
      "        [ 5.9182e-02,  8.4759e-02, -1.4332e-02,  1.3081e-02,  9.1533e-02,\n",
      "          5.7888e-02,  2.2596e-03, -4.1752e-02,  5.1148e-03,  8.5980e-02],\n",
      "        [ 6.5442e-02,  8.3851e-02, -6.7176e-03,  3.0516e-02,  9.6941e-02,\n",
      "          6.4674e-02,  1.4589e-02, -3.6927e-02,  2.6253e-03,  9.2149e-02],\n",
      "        [ 6.3122e-02,  8.7867e-02, -2.2842e-02,  1.2685e-02,  1.1377e-01,\n",
      "          5.4270e-02,  9.0480e-03, -4.5342e-02,  1.2464e-02,  9.0760e-02],\n",
      "        [ 6.9096e-02,  8.3655e-02, -1.7085e-02,  1.2717e-02,  1.0861e-01,\n",
      "          6.5463e-02,  1.5172e-02, -4.9945e-02,  8.8145e-03,  8.1964e-02],\n",
      "        [ 6.1187e-02,  9.4021e-02, -7.2252e-03,  2.5973e-02,  1.0005e-01,\n",
      "          6.0191e-02,  2.4447e-02, -4.3993e-02,  5.3945e-03,  8.2446e-02],\n",
      "        [ 7.2984e-02,  1.0121e-01, -1.1401e-02,  2.6299e-02,  1.0006e-01,\n",
      "          6.2076e-02,  1.6672e-02, -4.9560e-02,  5.1923e-03,  7.7050e-02],\n",
      "        [ 7.5742e-02,  9.6407e-02, -2.0549e-02,  2.8766e-02,  9.9514e-02,\n",
      "          7.6338e-02,  4.0497e-02, -4.4600e-02, -6.4374e-03,  8.8035e-02],\n",
      "        [ 5.7285e-02,  7.3714e-02,  8.6242e-04,  1.1552e-02,  9.2801e-02,\n",
      "          5.7966e-02, -2.6508e-03, -4.2349e-02,  1.2431e-02,  8.1365e-02],\n",
      "        [ 5.4777e-02,  8.1521e-02, -3.3031e-02,  2.4824e-02,  9.4184e-02,\n",
      "          6.8039e-02,  1.5034e-02, -3.9660e-02,  2.4782e-03,  8.6198e-02],\n",
      "        [ 7.1206e-02,  9.0431e-02, -1.5325e-02,  3.3546e-02,  9.0214e-02,\n",
      "          7.0534e-02,  2.5709e-02, -4.0404e-02, -4.7697e-03,  8.2646e-02],\n",
      "        [ 5.9284e-02,  8.4392e-02, -2.2107e-02,  2.3538e-03,  1.0787e-01,\n",
      "          5.9288e-02,  1.4695e-02, -5.1510e-02,  1.8638e-02,  9.6719e-02]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import mnist\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "def data_transform(x):\n",
    "    x = np.array(x, dtype = 'float32') / 255\n",
    "    x = x.reshape((-1, ))\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "trainset = mnist.MNIST('./dataset/mnist', train=True, transform=data_transform, download=True)\n",
    "testset = mnist.MNIST('./dataset/mnist', train = False, transform=data_transform, download=True)\n",
    "\n",
    "train_data = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 250)\n",
    "        self.fc3 = nn.Linear(250, 125)\n",
    "        self.fc4 = nn.Linear(125, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# build model\n",
    "model = DNN().to(device)\n",
    "\n",
    "\n",
    "model.train() # 告訴pytorch現在是訓練模式 可以調參數 可以dropout\n",
    "\n",
    "'''\n",
    "pred1 = model(trainset.train_data[0:5].reshape(-1,784).float())\n",
    "#pred1 = model(trainset.train_data[0].reshape(-1,784).float())\n",
    "print(pred1.shape)\n",
    "print(pred1)\n",
    "'''\n",
    "\n",
    "\n",
    "for im, label in train_data:\n",
    "    print(im.shape)\n",
    "    pred2 = model(im) \n",
    "    print(pred2.shape)\n",
    "    print(pred2)\n",
    "\n",
    "    break\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('AI_course')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "17351a460c7b6a87bea396add1443477c853166d48a66f1614cf7bf03cffca4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
