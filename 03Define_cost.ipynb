{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "#MSE Loss\n",
    "x = torch.Tensor([1,2,3])\n",
    "target = torch.Tensor([2,2,3])\n",
    "criterion = nn.MSELoss() # criterion(標準)\n",
    "loss = criterion(x,target)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9459, 0.6897])\n",
      "tensor(0.8178)\n",
      "tensor(1.6356)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "predict = torch.Tensor([[0.1,0.5,0.4],[0.1,0.1,0.8]])\n",
    "label = torch.LongTensor([1,2])\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\") # reduction = none 各自做各自的cross_entropy\n",
    "print(loss(predict,label))\n",
    "loss = nn.CrossEntropyLoss(reduction=\"mean\") # 再平均 (預設)\n",
    "print(loss(predict,label))\n",
    "loss = nn.CrossEntropyLoss(reduction=\"sum\") # 再加總\n",
    "print(loss(predict,label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "[4.55068    5.881681   7.8166313  0.75061125 7.8124557 ]\n",
      "5.362411975860596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\anaconda3\\envs\\AI_course\\lib\\site-packages\\torchvision\\datasets\\mnist.py:75: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "c:\\Users\\Student\\anaconda3\\envs\\AI_course\\lib\\site-packages\\torchvision\\datasets\\mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import mnist\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "def data_transform(x):\n",
    "    x = np.array(x, dtype = 'float32') / 255\n",
    "    x = x.reshape((-1, ))\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "trainset = mnist.MNIST('./dataset/mnist', train=True, transform=data_transform, download=True)\n",
    "testset = mnist.MNIST('./dataset/mnist', train = False, transform=data_transform, download=True)\n",
    "\n",
    "train_data = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 250)\n",
    "        self.fc3 = nn.Linear(250, 125)\n",
    "        self.fc4 = nn.Linear(125, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# build model\n",
    "model = DNN().to(device)\n",
    "criterion1 = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "\n",
    "pred = model(trainset.train_data[0:5].reshape(-1,784).float())\n",
    "\n",
    "# Calculate loss\n",
    "loss = criterion1(pred, trainset.train_labels[0:5])\n",
    "print(loss.detach().numpy())\n",
    "avg_loss = criterion2(pred, trainset.train_labels[0:5])\n",
    "print(avg_loss.item())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('AI_course')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "17351a460c7b6a87bea396add1443477c853166d48a66f1614cf7bf03cffca4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
