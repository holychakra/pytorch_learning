{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url:　https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "print(t.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "6\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]\n",
      "tensor([[3, 2, 1],\n",
      "        [1, 2, 3]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "a = t.Tensor([[1,2,3],[4,5,6]])\n",
    "a_numpy = a.numpy()\n",
    "a_list = a.tolist()\n",
    "\n",
    "b = np.array([[3,2,1],[1,2,3]])\n",
    "a_tensorf= t.from_numpy(b)\n",
    "\n",
    "print(a)\n",
    "print(a.numel())\n",
    "print(a_numpy)\n",
    "print(a_list)\n",
    "print(a_tensorf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "x2: [[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "x3: [1 2 3 4 5]\n",
      "x4: [ 0.   2.5  5.   7.5 10. ]\n",
      "x5: [[-0.99025804 -0.15802729  0.6870781 ]\n",
      " [-0.7288495   0.28516218 -1.2076206 ]]\n",
      "x6: [3 2 0 4 1]\n",
      "x7: [[1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "x1 = t.zeros(3,2)\n",
    "x2 = t.ones(4,3)\n",
    "x3 = t.arange(1, 6)\n",
    "x4 = t.linspace(0, 10, 5)\n",
    "x5 = t.randn(2, 3)\n",
    "x6 = t.randperm(5) # 0,1,2,3,4 洗牌\n",
    "x7 = t.eye(2, 3)\n",
    "\n",
    "\n",
    "print('x1: {}'.format(x1.numpy()))\n",
    "print('x2: {}'.format(x2.numpy()))\n",
    "print('x3: {}'.format(x3.numpy()))\n",
    "print('x4: {}'.format(x4.numpy()))\n",
    "print('x5: {}'.format(x5.numpy()))\n",
    "print('x6: {}'.format(x6.numpy()))\n",
    "print('x7: {}'.format(x7.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_num: [[17. 21.]\n",
      " [10. 12.]]\n",
      "sub_num: [[ 7.  9.]\n",
      " [-4. -4.]]\n",
      "mul_num: [[60. 90.]\n",
      " [21. 32.]]\n",
      "div_num: [[2.4        2.5       ]\n",
      " [0.42857143 0.5       ]]\n",
      "mod_num: [[2. 3.]\n",
      " [3. 4.]]\n",
      "neg_num: [[-12. -15.]\n",
      " [ -3.  -4.]]\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "x = t.Tensor([[12,15],[3,4]])\n",
    "y = t.Tensor([[5,6],[7,8]])\n",
    "\n",
    "sum_num = x + y\n",
    "sub_num = x - y\n",
    "mul_num = x * y\n",
    "div_num = x / y\n",
    "mod_num = x % y\n",
    "neg_num = -x\n",
    "\n",
    "print('sum_num: {}'.format(sum_num.numpy()))\n",
    "print('sub_num: {}'.format(sub_num.numpy()))\n",
    "print('mul_num: {}'.format(mul_num.numpy()))\n",
    "print('div_num: {}'.format(div_num.numpy()))\n",
    "print('mod_num: {}'.format(mod_num.numpy()))\n",
    "print('neg_num: {}'.format(neg_num.numpy()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_num: [[17. 21.]\n",
      " [10. 12.]]\n",
      "sub_num: [[ 7.  9.]\n",
      " [-4. -4.]]\n",
      "mul_num: [[60. 90.]\n",
      " [21. 32.]]\n",
      "div_num: [[2.4        2.5       ]\n",
      " [0.42857143 0.5       ]]\n",
      "mod_num: [[2. 3.]\n",
      " [3. 4.]]\n",
      "neg_num: [[-12. -15.]\n",
      " [ -3.  -4.]]\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "x = t.Tensor([[12,15],[3,4]])\n",
    "y = t.Tensor([[5,6],[7,8]])\n",
    "\n",
    "sum_num = t.add(x, y)\n",
    "sub_num = t.subtract(x, y)\n",
    "mul_num = t.multiply(x, y)\n",
    "div_num = t.divide(x, y)\n",
    "mod_num = t.remainder(x,y)\n",
    "neg_num = t.negative(x)\n",
    "\n",
    "print('sum_num: {}'.format(sum_num.numpy()))\n",
    "print('sub_num: {}'.format(sub_num.numpy()))\n",
    "print('mul_num: {}'.format(mul_num.numpy()))\n",
    "print('div_num: {}'.format(div_num.numpy()))\n",
    "print('mod_num: {}'.format(mod_num.numpy()))\n",
    "print('neg_num: {}'.format(neg_num.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6186, -0.3720, -0.3310],\n",
      "        [ 0.2823,  0.7218, -2.2301]])\n",
      "tensor([[-1.3382,  1.3895, -1.6067],\n",
      "        [-2.4899,  4.4647, -5.0102],\n",
      "        [-0.6420,  1.2979, -2.4253]])\n",
      "tensor([[-1.0272, -0.7432],\n",
      "        [ 0.1584,  0.7205],\n",
      "        [ 0.0661,  1.3388]])\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "x1 = t.randn(2, 3)\n",
    "x2 = t.randn(3, 3)\n",
    "\n",
    "matrix_product = t.mm(x1, x2) # 矩陣相乘\n",
    "matrix_inv = t.inverse(x2) # 逆運算\n",
    "matrix_trans = t.transpose(x1,0, 1) # 行列對調\n",
    "\n",
    "print(matrix_product)\n",
    "print(matrix_inv)\n",
    "print(matrix_trans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Type  \n",
    "\n",
    "\n",
    "| Data type                | dtype                             | CPU tensor                                                   | GPU tensor                |\n",
    "| ------------------------ | --------------------------------- | ------------------------------------------------------------ | ------------------------- |\n",
    "| 32-bit floating point    | `torch.float32` or `torch.float`  | `torch.FloatTensor`                                          | `torch.cuda.FloatTensor`  |\n",
    "| 64-bit floating point    | `torch.float64` or `torch.double` | `torch.DoubleTensor`                                         | `torch.cuda.DoubleTensor` |\n",
    "| 16-bit floating point    | `torch.float16` or `torch.half`   | `torch.HalfTensor`                                           | `torch.cuda.HalfTensor`   |\n",
    "| 8-bit integer (unsigned) | `torch.uint8`                     | [`torch.ByteTensor`](https://pytorch.org/docs/stable/tensors.html#torch.ByteTensor) | `torch.cuda.ByteTensor`   |\n",
    "| 8-bit integer (signed)   | `torch.int8`                      | `torch.CharTensor`                                           | `torch.cuda.CharTensor`   |\n",
    "| 16-bit integer (signed)  | `torch.int16` or `torch.short`    | `torch.ShortTensor`                                          | `torch.cuda.ShortTensor`  |\n",
    "| 32-bit integer (signed)  | `torch.int32` or `torch.int`      | `torch.IntTensor`                                            | `torch.cuda.IntTensor`    |\n",
    "| 64-bit integer (signed)  | `torch.int64` or `torch.long`     | `torch.LongTensor`                                           | `torch.cuda.LongTensor`   |\n",
    "  \n",
    "FloatTensor ->  'float32'  \n",
    "\n",
    "DoubleTensor -> 'float64'  \n",
    "\n",
    "ShortTensor -> 'int16'  \n",
    "\n",
    "IntTensor -> 'int32'  \n",
    "\n",
    "LongTensor -> 'int64'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float64\n",
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    "a = t.Tensor([[1,2,3],[4,5,6]])\n",
    "print(a.dtype)\n",
    "a_double = a.double()   #'float64'\n",
    "print(a_double.dtype)\n",
    "\n",
    "a_int = a.int()      #'int32'\n",
    "print(a_int.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "tensor(1.)\n",
      "tensor(-15.)\n",
      "tensor(12.)\n",
      "tensor([[12., 15.],\n",
      "        [ 3.,  4.]])\n",
      "======\n",
      "tensor([ 15., -11.])\n",
      "tensor([ 7.5000, -5.5000])\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "x = t.Tensor([[12,-15],[3,4]])\n",
    "\n",
    "print(t.sum(x))\n",
    "print(t.mean(x))\n",
    "print(t.min(x))\n",
    "print(t.max(x))\n",
    "print(t.abs(x))\n",
    "\n",
    "print('======')\n",
    "\n",
    "print(t.sum(x, dim=0))\n",
    "print(t.mean(x, dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 0])\n",
      "tensor([0, 2, 2])\n",
      "tensor([2, 0, 0])\n",
      "tensor([0, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = t.Tensor([[1.1, 2.2, 3.3],[4.5, 3.2, 2.1], [5, 0, -2]])\n",
    "print(t.argmax(x, dim=0))\n",
    "print(t.argmin(x, dim=0))\n",
    "print(t.argmax(x, dim=1))\n",
    "print(t.argmin(x, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [1, 1],\n",
      "        [1, 1]]) torch.int64\n",
      "tensor([0.9915, 0.8603, 0.0479]) torch.float32\n",
      "tensor([[0.7480, 0.4521],\n",
      "        [0.3486, 0.0226],\n",
      "        [0.4164, 0.7220]], dtype=torch.float64) torch.float64\n",
      "tensor([[-0.7488, -1.8626,  3.4863],\n",
      "        [ 1.3063, -0.5515,  0.2597],\n",
      "        [-1.0984, -0.1756, -1.6848],\n",
      "        [-0.7209, -0.8977, -0.9230]], dtype=torch.float64) torch.float64\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "a=t.randint(0,3,(3,2)) #3*2形狀 0-3\n",
    "b=t.rand(3)\n",
    "c=t.rand(3,2,dtype=t.double)\n",
    "d=t.randn(4,3,dtype=t.double) # 高斯常態分佈\n",
    "\n",
    "print(a,a.dtype)\n",
    "print(b,b.dtype)\n",
    "print(c,c.dtype)\n",
    "print(d,d.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(2.)\n",
      "tensor([4., 5., 6.])\n",
      "tensor([3., 6., 9.])\n"
     ]
    }
   ],
   "source": [
    "x = t.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(x[0,0])\n",
    "print(x[0,1])\n",
    "print(x[1,:])\n",
    "print(x[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshape & flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9., 10., 11.,  1.]])\n",
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9., 10., 11.,  1.]])\n",
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.],\n",
      "         [ 5.,  6.]],\n",
      "\n",
      "        [[ 7.,  8.],\n",
      "         [ 9., 10.],\n",
      "         [11.,  1.]]])\n",
      "==========\n",
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9., 10., 11.,  1.]])\n",
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9., 10., 11.,  1.]])\n",
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.],\n",
      "         [ 5.,  6.]],\n",
      "\n",
      "        [[ 7.,  8.],\n",
      "         [ 9., 10.],\n",
      "         [11.,  1.]]])\n",
      "==========\n",
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.,  1.])\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "x =  t.Tensor([\n",
    "    [1,2,3,4],\n",
    "    [5,6,7,8],\n",
    "    [9,10,11,1]\n",
    "])\n",
    "print(x.shape)\n",
    "print(x.reshape([2,6]))\n",
    "print(x.reshape([2,-1]))\n",
    "print(x.reshape([2,3,-1]))\n",
    "\n",
    "# view V.S. reshape (另一種寫法)\n",
    "# ref: https://www.codenong.com/cs105381089/\n",
    "print('==========')\n",
    "print(x.view([2,6]))\n",
    "print(x.view([2,-1]))\n",
    "print(x.view([2,3,-1]))\n",
    "\n",
    "print('==========')\n",
    "print(x.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[1., 2., 5., 6.]])\n",
      "tensor([[1., 2., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x =  t.Tensor([\n",
    "    [1,2],\n",
    "    [5,6],\n",
    "\n",
    "])\n",
    "print(x.is_contiguous()) # 是否連續\n",
    "print(x.reshape([1,4]))\n",
    "print(x.view([1,4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([[1., 5., 2., 6.]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Student\\Desktop\\GITHUBTEST\\pytorch_notes\\basic_pytorch.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Student/Desktop/GITHUBTEST/pytorch_notes/basic_pytorch.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mis_contiguous())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Student/Desktop/GITHUBTEST/pytorch_notes/basic_pytorch.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mreshape([\u001b[39m1\u001b[39m,\u001b[39m4\u001b[39m]))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Student/Desktop/GITHUBTEST/pytorch_notes/basic_pytorch.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39;49mview([\u001b[39m1\u001b[39;49m,\u001b[39m4\u001b[39;49m]))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "x = x.permute(1,0)\n",
    "print(x.is_contiguous())\n",
    "print(x.reshape([1,4]))\n",
    "print(x.view([1,4]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeeze & Unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n",
      "torch.Size([1, 6])\n",
      "torch.Size([6, 1])\n",
      "======\n",
      "torch.Size([1, 2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = t.Tensor([1,2,3,4,5,6])\n",
    "y = x.unsqueeze(dim=0)\n",
    "z = x.unsqueeze(dim=1)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)\n",
    "print('======')\n",
    "\n",
    "x = t.Tensor([[[1,2,3],[4,5,6]]])\n",
    "y = x.squeeze(dim=0)\n",
    "z = x.squeeze(dim=2)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape) # 只會擠掉 數字為1的維度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Activation Function  \n",
    "![activation](./images/activation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7311, 0.1192, 0.9526],\n",
      "        [0.0180, 0.9933, 0.9975]])\n",
      "tensor([[ 0.7616, -0.9640,  0.9951],\n",
      "        [-0.9993,  0.9999,  1.0000]])\n",
      "tensor([[1., 0., 3.],\n",
      "        [0., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = t.Tensor([[1,-2,3],[-4,5,6]])\n",
    "sig_result = t.sigmoid(x)\n",
    "tanh_result = t.tanh(x)\n",
    "relu_result = t.relu(x)\n",
    "\n",
    "print(sig_result)\n",
    "print(tanh_result)\n",
    "print(relu_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset/DataLoader  \n",
    " \n",
    "- `__getitem__`：返回一個數據樣本(`obj[index]`等價於`obj.__getitem__(index)`)\n",
    "- `__len__`：返回樣本的數量(`len(obj)`等價於`obj.__len__()`)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "tensor([11., 12., 13., 14., 15., 16., 17., 18., 19., 20.])\n",
      "Epoch:  0 | Step:  0 | batch x:  [ 2. 10.  9.  4.  7.] | batch y:  [12. 20. 19. 14. 17.]\n",
      "Epoch:  0 | Step:  1 | batch x:  [3. 1. 6. 8. 5.] | batch y:  [13. 11. 16. 18. 15.]\n",
      "Epoch:  1 | Step:  0 | batch x:  [ 1.  3.  7.  4. 10.] | batch y:  [11. 13. 17. 14. 20.]\n",
      "Epoch:  1 | Step:  1 | batch x:  [2. 6. 9. 8. 5.] | batch y:  [12. 16. 19. 18. 15.]\n",
      "Epoch:  2 | Step:  0 | batch x:  [4. 3. 6. 7. 8.] | batch y:  [14. 13. 16. 17. 18.]\n",
      "Epoch:  2 | Step:  1 | batch x:  [ 5.  1.  9. 10.  2.] | batch y:  [15. 11. 19. 20. 12.]\n",
      "Epoch:  3 | Step:  0 | batch x:  [6. 1. 9. 4. 3.] | batch y:  [16. 11. 19. 14. 13.]\n",
      "Epoch:  3 | Step:  1 | batch x:  [ 5.  8. 10.  2.  7.] | batch y:  [15. 18. 20. 12. 17.]\n",
      "Epoch:  4 | Step:  0 | batch x:  [9. 6. 1. 3. 2.] | batch y:  [19. 16. 11. 13. 12.]\n",
      "Epoch:  4 | Step:  1 | batch x:  [ 5.  4.  8.  7. 10.] | batch y:  [15. 14. 18. 17. 20.]\n",
      "Epoch:  5 | Step:  0 | batch x:  [ 5. 10.  8.  2.  9.] | batch y:  [15. 20. 18. 12. 19.]\n",
      "Epoch:  5 | Step:  1 | batch x:  [7. 3. 1. 4. 6.] | batch y:  [17. 13. 11. 14. 16.]\n",
      "Epoch:  6 | Step:  0 | batch x:  [8. 6. 5. 3. 9.] | batch y:  [18. 16. 15. 13. 19.]\n",
      "Epoch:  6 | Step:  1 | batch x:  [ 2.  7.  1. 10.  4.] | batch y:  [12. 17. 11. 20. 14.]\n",
      "Epoch:  7 | Step:  0 | batch x:  [8. 7. 5. 1. 3.] | batch y:  [18. 17. 15. 11. 13.]\n",
      "Epoch:  7 | Step:  1 | batch x:  [ 6.  9.  4.  2. 10.] | batch y:  [16. 19. 14. 12. 20.]\n",
      "Epoch:  8 | Step:  0 | batch x:  [ 8. 10.  7.  4.  2.] | batch y:  [18. 20. 17. 14. 12.]\n",
      "Epoch:  8 | Step:  1 | batch x:  [6. 5. 3. 9. 1.] | batch y:  [16. 15. 13. 19. 11.]\n",
      "Epoch:  9 | Step:  0 | batch x:  [ 6.  1.  8.  5. 10.] | batch y:  [16. 11. 18. 15. 20.]\n",
      "Epoch:  9 | Step:  1 | batch x:  [3. 9. 4. 7. 2.] | batch y:  [13. 19. 14. 17. 12.]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "x = torch.linspace(1, 10, 10)\n",
    "y = torch.linspace(11, 20, 10)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "torch_dataset = TensorDataset(x, y)\n",
    "loader = DataLoader(dataset=torch_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0 ) # num_worker= 核心數\n",
    "\n",
    "for epoch in range(10):\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        print('Epoch: ', epoch, '| Step: ', step, '| batch x: ', batch_x.numpy(), '| batch y: ', batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.    148.     72.     35.      0.     33.6     0.627  50.   ]\n",
      "1\n",
      "torch.Size([5, 8])\n",
      "torch.Size([5])\n",
      "tensor([[3.0000e+00, 1.9300e+02, 7.0000e+01, 3.1000e+01, 0.0000e+00, 3.4900e+01,\n",
      "         2.4100e-01, 2.5000e+01],\n",
      "        [2.0000e+00, 8.8000e+01, 7.4000e+01, 1.9000e+01, 5.3000e+01, 2.9000e+01,\n",
      "         2.2900e-01, 2.2000e+01],\n",
      "        [7.0000e+00, 1.4700e+02, 7.6000e+01, 0.0000e+00, 0.0000e+00, 3.9400e+01,\n",
      "         2.5700e-01, 4.3000e+01],\n",
      "        [3.0000e+00, 1.7300e+02, 8.4000e+01, 3.3000e+01, 4.7400e+02, 3.5700e+01,\n",
      "         2.5800e-01, 2.2000e+01],\n",
      "        [1.0000e+00, 1.9900e+02, 7.6000e+01, 4.3000e+01, 0.0000e+00, 4.2900e+01,\n",
      "         1.3940e+00, 2.2000e+01]], dtype=torch.float64)\n",
      "tensor([1, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Mydataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        return a single data and a corresponding single label\n",
    "        \"\"\"\n",
    "        df = pd.read_csv('./dataset/pima-indians-diabetes.csv')\n",
    "        #print(df.head(3))\n",
    "        \n",
    "        self.labels = df['label']\n",
    "        self.dataset = df.drop('label', axis=1)\n",
    "        \n",
    "        self.labels = np.asarray(self.labels)\n",
    "        self.dataset = np.asarray(self.dataset)\n",
    "        \n",
    "        #print(self.labels[:5])        \n",
    "        #print(self.dataset[:5])\n",
    "        \n",
    "        ## add normalization to here if you want\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        return a single data and a corresponding single label\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        return self.dataset[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        return total data length\n",
    "        \"\"\"\n",
    "        \n",
    "        return len(self.dataset)\n",
    "my_data = Mydataset()\n",
    "data, label = my_data[0]\n",
    "\n",
    "print(data)\n",
    "print(label)\n",
    "\n",
    "'''\n",
    "for data, label in my_data:\n",
    "    print(data)\n",
    "    print(label)\n",
    "    print('===')\n",
    "'''\n",
    "\n",
    "my_data_loader = DataLoader(my_data, batch_size=5, shuffle=True)\n",
    "\n",
    "for batch_data, batch_labels in my_data_loader:\n",
    "    print(batch_data.shape)\n",
    "    print(batch_labels.shape)\n",
    "    print(batch_data)\n",
    "    print(batch_labels)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient\n",
    "微分\n",
    "一定要requires_grad = ture 才會被微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.ones((1,))\n",
    "print(x.requires_grad)\n",
    "\n",
    "x = torch.ones((1,), requires_grad=True)\n",
    "print(x.requires_grad)\n",
    "\n",
    "y = torch.zeros((1,))\n",
    "print(y.requires_grad)\n",
    "\n",
    "z = 2*x + y             # x可以微 ， y不可以微，相加之後的z可以微。\n",
    "print(z.requires_grad)\n",
    "\n",
    "y.requires_grad_(True)\n",
    "print(y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones((1,), requires_grad=True)\n",
    "y = 2*x*x - x + 3\n",
    "y.backward() # 對y裡面所有可微的數字，做偏微。\n",
    "print(x.grad)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  7., 11.],\n",
      "        [15., 19., 23.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "x.requires_grad_(True)\n",
    "y = 2*x*x - x + 3\n",
    "y.backward(torch.ones(2,3)) #裡面都是1 ;*1\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6., 14., 22.],\n",
      "        [30., 38., 46.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "x.requires_grad_(True)\n",
    "y = 2*x*x - x + 3\n",
    "y.backward(torch.ones(2,3)+1) #裡面都變2了 ;*2\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y = x^2\\bullet e^x\n",
    "$$\n",
    "\n",
    "$$\n",
    "{dy \\over dx} = 2x\\bullet e^x + x^2 \\bullet e^x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4434, -0.4146,  0.5804,  6.6260],\n",
      "        [-0.4611, -0.1204, -0.4467,  1.5245],\n",
      "        [-0.2429,  3.7458, 13.3933, -0.4415]])\n",
      "tensor([[-0.4434, -0.4146,  0.5804,  6.6260],\n",
      "        [-0.4611, -0.1204, -0.4467,  1.5245],\n",
      "        [-0.2429,  3.7458, 13.3933, -0.4415]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    y = x**2 * t.exp(x)\n",
    "    return y\n",
    "\n",
    "def gradf(x): \n",
    "    dx = 2*x*t.exp(x) + x**2*t.exp(x)\n",
    "    return dx\n",
    "\n",
    "x = t.randn(3,4, requires_grad = True)\n",
    "y = f(x)\n",
    "\n",
    "y.backward(t.ones(y.size())) \n",
    "print(x.grad)\n",
    "print(gradf(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2500], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "x = torch.ones((1,), requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.SGD([x], lr=learning_rate)\n",
    "#optimizer = torch.optim.RMSprop([x], lr=learning_rate, alpha=0.9)\n",
    "#optimizer = torch.optim.Adam([x], lr=learning_rate, betas=(0.9, 0.99))\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    y = 2*x*x-x+3\n",
    "    \n",
    "    optimizer.zero_grad() #清空優化器\n",
    "    y.backward()\n",
    "    optimizer.step()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('AI_course')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "17351a460c7b6a87bea396add1443477c853166d48a66f1614cf7bf03cffca4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
